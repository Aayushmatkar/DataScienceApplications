{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushmatkar/DataScienceApplications/blob/main/final%20GROUP12_ASSIGNMENT_1(classification).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lib imports "
      ],
      "metadata": {
        "id": "-vgZAyhRcEEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi_FBGHQ2oyJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "#MODEL IMPORTS\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "#VALIDATION METRICS\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA PREPARATION AND CLEANING "
      ],
      "metadata": {
        "id": "b3-oDwd56XIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "import re\n",
        "import os,random\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "def create_partitions(text, book_name, author):\n",
        "    partitions = []\n",
        "    words = nltk.word_tokenize(text)\n",
        "    for i in range(0, len(words), 100):\n",
        "        partitions.append((words[i:i+100], book_name, author))\n",
        "    return partitions\n",
        "\n",
        "#The books selected below are from the gutenberg module and are of the same genre 'novel'\n",
        "book_names=['melville-moby_dick.txt','edgeworth-parents.txt','chesterton-thursday.txt','austen-emma.txt','milton-paradise.txt']\n",
        "\n",
        "def random_sentences_with_book_name():\n",
        "  result=pd.DataFrame(columns=['Text', 'Book Name','Author'])\n",
        "  for i in book_names:\n",
        "    # Splitting the book names to remove their 'txt' extension\n",
        "    label_name=i.split('.')[0]\n",
        "\n",
        "    # Getting the book names from Gutenberg and reading them\n",
        "    book = gutenberg.raw(i)\n",
        "\n",
        "    #Getting the book names and their respective authors\n",
        "    lines = book.splitlines()\n",
        "\n",
        "    #The first line consists information about the above comment\n",
        "    line1=lines[0]\n",
        "    \n",
        "    #Removing the year from the line\n",
        "    pattern = r'\\D+'\n",
        "\n",
        "    digits_removed = re.findall(pattern, line1)\n",
        "\n",
        "    #Getting the author name\n",
        "    author = re.search(r'\\sby\\s([\\w\\s\\.]+)[\\s\\d{4}]+', digits_removed[0]).group(1)\n",
        "\n",
        "    #Getting the book name\n",
        "    book_name = re.search(r'\\[([\\w\\s\\']+)[\\,]?\\sby', line1).group(1)\n",
        "\n",
        "    # Create partitions of 100 words each\n",
        "    partitions = create_partitions(book, book_name, author)\n",
        "\n",
        "    # Create 200 random samples of the partitions\n",
        "    samples = random.sample(partitions, 200)\n",
        "\n",
        "    # Using regular expressions to clean the data\n",
        "    for i in range(len(samples)):\n",
        "        samples[i] = (re.sub(r'[^\\w\\s]','', ' '.join(samples[i][0])), samples[i][1], samples[i][2])\n",
        "\n",
        "    # Serialize the data using Pandas\n",
        "    df = pd.DataFrame(samples, columns=['Text', 'Book Name','Author'])\n",
        "\n",
        "    #Appending the random sentences of a book to the final dataframe \n",
        "    result=pd.concat([result,df])\n",
        "  result.to_csv('book_partitions.csv', index=False)\n",
        "\n",
        "  print(\"Data saved to book_partitions.csv.\")"
      ],
      "metadata": {
        "id": "Tr_F5G3_7Cyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentences_with_book_name()\n",
        "data=pd.read_csv('book_partitions.csv')\n",
        "data['Author'].value_counts(),data['Author'].unique()\n",
        "data['Book Name'].value_counts(),data['Book Name'].unique()"
      ],
      "metadata": {
        "id": "uaK7gu9Z7HF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label']='a'\n",
        "data['index']=0\n",
        "data['label'][200:400]='b'\n",
        "data['index'][200:400]=1\n",
        "data['label'][400:600]='c'\n",
        "data['index'][400:600]=2\n",
        "data['label'][600:800]='d'\n",
        "data['index'][600:800]=3\n",
        "data['label'][800:1000]='e'\n",
        "data['index'][800:1000]=4"
      ],
      "metadata": {
        "id": "eZJnMFDQ7Np8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data\n"
      ],
      "metadata": {
        "id": "ltXTzyO97dJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot word cloud for the most frequent 20 words in each book  \n",
        "import wordcloud\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "for label in data['label'].unique():\n",
        "  books = data[data[\"label\"]==label][\"Text\"]\n",
        "\n",
        "\n",
        "# Create word cloud\n",
        "  wc = wordcloud.WordCloud(background_color=None, max_words=20, \n",
        "                          max_font_size=100)\n",
        "  wc = wc.generate(str(books))\n",
        "\n",
        "# Convert word cloud to dataframe\n",
        "  words = list(wc.words_.keys())\n",
        "  freq = [wc.words_[word] for word in words]\n",
        "  data10 = {'words': words, 'freq': freq}\n",
        "  df10 = pd.DataFrame(data10)\n",
        "\n",
        "  # Create interactive word cloud\n",
        "  fig = px.scatter(df10, x='words', y='freq', text='words', size='freq', color='freq')\n",
        "  fig.update_layout(title='Interactive Word Cloud',\n",
        "                    xaxis_title='Words',\n",
        "                    yaxis_title='Frequency')\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "HCUxgs-z5Eo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BAG OF WORDS "
      ],
      "metadata": {
        "id": "q9deQGG_7gjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Convert the text data into a tf-idf representation\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "bag_of_words = vectorizer.fit_transform(data['Text'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, data['Author'], test_size=0.2)\n",
        "\n",
        "\n",
        "# K-NEAREST NEIGHBOU train and evaluate \n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred,average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred,average='macro')\n",
        "knn_fscore = f1_score (y_test, knn_pred,average='macro')\n",
        "\n",
        "print('knn_accuracy with Bag of Words = ',knn_accuracy)\n",
        "print('knn_precision with Bag of Words = ',knn_precision)\n",
        "print('knn_recall with Bag of Words = ',knn_recall)\n",
        "print('knn_Fscore with Bag of Words = ',knn_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#DECISION TREE \n",
        "# Train and evaluate the Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred,average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred,average='macro')\n",
        "dt_fscore = f1_score (y_test, dt_pred,average='macro')\n",
        "\n",
        "print('dt_accuracy with Bag of Words  = ',dt_accuracy)\n",
        "print('dt_precision with Bag of Words = ',dt_precision)\n",
        "print('dt_recall with Bag of Words = ',dt_recall)\n",
        "print('dt_Fscore with Bag of Words = ',dt_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred,average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred,average='macro')\n",
        "svm_fscore = f1_score (y_test, svm_pred,average='macro')\n",
        "\n",
        "\n",
        "print('svm_accuracy with Bag of Words = ',svm_accuracy)\n",
        "print('svm_precision with Bag of Words = ',svm_precision)\n",
        "print('svm_recall with Bag of Words = ',svm_recall)\n",
        "print('svm_Fscore with Bag of Words = ',svm_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Train and evaluate the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "xgb_precision = precision_score(y_test, xgb_pred,average='macro')\n",
        "xgb_recall = recall_score(y_test, xgb_pred,average='macro')\n",
        "xgb_fscore = f1_score (y_test, xgb_pred,average='macro')\n",
        "\n",
        "\n",
        "print('xgb_accuracy with Bag of Words = ',xgb_accuracy)\n",
        "print('xgb_precision with Bag of Words = ',xgb_precision)\n",
        "print('xgb_recall with Bag of Words = ',xgb_recall)\n",
        "print('xgb_Fscore with Bag of Words = ',xgb_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Plot the accuracy comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "accuracies = [knn_accuracy, svm_accuracy,dt_accuracy, xgb_accuracy]\n",
        "plt.bar(models, accuracies)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Precision comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "precisions = [knn_precision, svm_precision,dt_precision, xgb_precision]\n",
        "plt.bar(models, precisions)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('precision')\n",
        "plt.title('Precision comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Recall comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "recalls = [knn_recall, svm_recall,dt_recall, xgb_recall]\n",
        "plt.bar(models, recalls)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Fscore comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "fscores = [knn_fscore, svm_fscore,dt_fscore, xgb_fscore]\n",
        "plt.bar(models, fscores)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Fscore')\n",
        "plt.title('Fscore comparison of models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rEylRDYb7pFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFUSION MATRIX AND ERROR ANALYSIS FOR BAG OF WORDS "
      ],
      "metadata": {
        "id": "pKvq_Eus-raY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "nbXCo4yvNH3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM ERROR ANALYSIS AND CONFUSION MATRIX "
      ],
      "metadata": {
        "id": "Or4s8KC-Pt5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "svm_pred = svm.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=svm_pred\n",
        "df"
      ],
      "metadata": {
        "id": "DTHBFHi77vVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the SVM model with Bag Of Words are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), svm_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the SVM model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "pxajwBMiQZ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), svm_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for SVM Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gi42wF4O5Nzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KNN ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "ZLhoyjkLTOxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "knn_pred = knn.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=knn_pred\n",
        "df"
      ],
      "metadata": {
        "id": "NXKHC6PURfQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the KNN model with Bag Of Words are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), knn_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the KNN model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fd12OHAGNExq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test.to_numpy(), knn_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for KNN Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SC68FTfA5TeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "EsVqJ5NLTGwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "dt_pred = dt.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=dt_pred\n",
        "df"
      ],
      "metadata": {
        "id": "bpGxUGYxSOPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the decision tree model with Bag Of Words are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), dt_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the Decision Tree model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "Qg662q5DSPGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test.to_numpy(), dt_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for Decision Tree Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yGV3hkTi5WPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost ERROR AND CONFUSION MATRIX "
      ],
      "metadata": {
        "id": "vZ-MUDVRS85u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=xgb_pred\n",
        "df"
      ],
      "metadata": {
        "id": "OElenV6nSiK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the XGBoost model with Bag Of Words are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), xgb_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the XGBoost model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "po-titOrSj3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test.to_numpy(), xgb_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for XGBoost Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iZ69yLC05aZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10 fold cross validation"
      ],
      "metadata": {
        "id": "cuos7m8jo7E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def ten_fold_cross_validation(model, X, y):\n",
        "    kf = KFold(n_splits=10)\n",
        "    accuracy = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy.append(model.score(X_test, y_test))\n",
        "    \n",
        "    return np.array(accuracy)\n"
      ],
      "metadata": {
        "id": "_fh1K6NIpA2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for SVM \\n\")\n",
        "accuracies=ten_fold_cross_validation(svm,bag_of_words,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for SVM model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "Yv-ceDfrqDJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for KNN \\n\")\n",
        "accuracies=ten_fold_cross_validation(knn,bag_of_words,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for KNN model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "5Gc1DCJDrni1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for Decision Tree \\n\")\n",
        "accuracies=ten_fold_cross_validation(dt,bag_of_words,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for Decision Tree model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "lVhf-WzHr3TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for XGB \\n\")\n",
        "accuracies=ten_fold_cross_validation(xgb_model,bag_of_words,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for XGB model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "LGXJbLxTr8PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF "
      ],
      "metadata": {
        "id": "p7nYog7L_-AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the csv file\n",
        "#df = pd.read_csv('book_partitions.csv')\n",
        "\n",
        "# Convert the text data into a tf-idf representation\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf = vectorizer.fit_transform(data['Text'].values)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, data['Author'], test_size=0.2, random_state=42)\n",
        "\n",
        "# K-NEAREST NEIGHBOUR \n",
        "# Train and evaluate the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred,average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred,average='macro')\n",
        "knn_fscore = f1_score (y_test, knn_pred,average='macro')\n",
        "\n",
        "print('knn_accuracy with TF-IDF = ',knn_accuracy)\n",
        "print('knn_precision with TF-IDF = ',knn_precision)\n",
        "print('knn_recall with TF-IDF = ',knn_recall)\n",
        "print('knn_Fscore with TF-IDF = ',knn_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#DECISION TREE \n",
        "# Train and evaluate the Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred,average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred,average='macro')\n",
        "dt_fscore = f1_score (y_test, dt_pred,average='macro')\n",
        "\n",
        "print('dt_accuracy with TF-IDF  = ',dt_accuracy)\n",
        "print('dt_precision with TF-IDF = ',dt_precision)\n",
        "print('dt_recall with TF-IDF = ',dt_recall)\n",
        "print('dt_Fscore with TF-IDF = ',dt_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred,average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred,average='macro')\n",
        "svm_fscore = f1_score (y_test, svm_pred,average='macro')\n",
        "\n",
        "\n",
        "print('svm_accuracy with TF-IDF = ',svm_accuracy)\n",
        "print('svm_precision with TF-IDF = ',svm_precision)\n",
        "print('svm_recall with TF-IDF = ',svm_recall)\n",
        "print('svm_Fscore with TF-IDF = ',svm_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Train and evaluate the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "xgb_precision = precision_score(y_test, xgb_pred,average='macro')\n",
        "xgb_recall = recall_score(y_test, xgb_pred,average='macro')\n",
        "xgb_fscore = f1_score (y_test, xgb_pred,average='macro')\n",
        "\n",
        "\n",
        "print('xgb_accuracy with TF-IDF = ',xgb_accuracy)\n",
        "print('xgb_precision with TF-IDF = ',xgb_precision)\n",
        "print('xgb_recall with TF-IDF = ',xgb_recall)\n",
        "print('xgb_Fscore with TF-IDF = ',xgb_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Plot the accuracy comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "accuracies = [knn_accuracy, svm_accuracy,dt_accuracy, xgb_accuracy]\n",
        "plt.bar(models, accuracies)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Precision comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "precisions = [knn_precision, svm_precision,dt_precision, xgb_precision]\n",
        "plt.bar(models, precisions)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('precision')\n",
        "plt.title('Precision comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Recall comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "recalls = [knn_recall, svm_recall,dt_recall, xgb_recall]\n",
        "plt.bar(models, recalls)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Fscore comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "fscores = [knn_fscore, svm_fscore,dt_fscore, xgb_fscore]\n",
        "plt.bar(models, fscores)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Fscore')\n",
        "plt.title('Fscore comparison of models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yx6wf56gAETF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CONFUSION MATRIX AND ERROR ANALYSIS FOR TF-IDF"
      ],
      "metadata": {
        "id": "_ZOl_Yz7XOoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "zPqn7RgYCw90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM ERROR ANALYSIS AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "zJTHqpfrXafm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "svm_pred = svm.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=svm_pred\n",
        "df"
      ],
      "metadata": {
        "id": "THLaZixJCxzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the SVM model with TF-IDF are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), svm_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the SVM model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "HsA6PbcZAK1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for SVM Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NPmKSdXI6b3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "32OTYvBQXtM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "knn_pred = knn.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=knn_pred\n",
        "df"
      ],
      "metadata": {
        "id": "rZUWnrCkXvpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the KNN model with TF-IDF are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), knn_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the KNN model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "DWUSNdJSXyrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for KNN Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5-nXxHX960pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "Z9_8RD-jX3UX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "dt_pred = dt.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=dt_pred\n",
        "df"
      ],
      "metadata": {
        "id": "ihlu8T-jX7_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the decision tree model with TF-IDF are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), dt_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the Decision Tree model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "cdLW--IPX-HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for Decision Tree Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xecxyejl63lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "SXZ8PyQ3YEnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=xgb_pred\n",
        "df"
      ],
      "metadata": {
        "id": "YYvDh3IYYHce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the XGBoost model with TF-IDF are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), xgb_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the XGBoost model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "I-dJQQvEYImm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for XGBoost Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qACg7u3T66az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Fold Cross Validation"
      ],
      "metadata": {
        "id": "yG7Li-ZBsWx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for SVM \\n\")\n",
        "accuracies=ten_fold_cross_validation(svm,tfidf,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for SVM model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "xijMtOxJsaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for KNN \\n\")\n",
        "accuracies=ten_fold_cross_validation(knn,tfidf,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for KNN model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "V_FLU970srk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for Decision Tree \\n\")\n",
        "accuracies=ten_fold_cross_validation(dt,tfidf,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for Decision Tree model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "YBfDJ08jsspR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for XGB \\n\")\n",
        "accuracies=ten_fold_cross_validation(xgb_model,tfidf,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for XGB model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "kdW7YSfTsxqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-GRAM\n"
      ],
      "metadata": {
        "id": "nnu3qK1vAx4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the csv file\n",
        "#df = pd.read_csv('book_partitions3.csv')\n",
        "\n",
        "# Convert the text data into a n-gram representation\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "ngrams = vectorizer.fit_transform(data['Text'].values)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngrams, data['Author'], test_size=0.2, random_state=42)\n",
        "\n",
        "# K-NEAREST NEIGHBOUR \n",
        "# Train and evaluate the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred,average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred,average='macro')\n",
        "knn_fscore = f1_score (y_test, knn_pred,average='macro')\n",
        "\n",
        "print('knn_accuracy with N-GRAM = ',knn_accuracy)\n",
        "print('knn_precision with N-GRAM = ',knn_precision)\n",
        "print('knn_recall with N-GRAM = ',knn_recall)\n",
        "print('knn_Fscore with N-GRAM = ',knn_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#DECISION TREE \n",
        "# Train and evaluate the Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred,average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred,average='macro')\n",
        "dt_fscore = f1_score (y_test, dt_pred,average='macro')\n",
        "\n",
        "print('dt_accuracy with N-GRAM  = ',dt_accuracy)\n",
        "print('dt_precision with N-GRAM = ',dt_precision)\n",
        "print('dt_recall with N-GRAM = ',dt_recall)\n",
        "print('dt_Fscore with N-GRAM = ',dt_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred,average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred,average='macro')\n",
        "svm_fscore = f1_score (y_test, svm_pred,average='macro')\n",
        "\n",
        "\n",
        "print('svm_accuracy with N-GRAM = ',svm_accuracy)\n",
        "print('svm_precision with N-GRAM = ',svm_precision)\n",
        "print('svm_recall with N-GRAM = ',svm_recall)\n",
        "print('svm_Fscore with N-GRAM = ',svm_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Train and evaluate the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "xgb_precision = precision_score(y_test, xgb_pred,average='macro')\n",
        "xgb_recall = recall_score(y_test, xgb_pred,average='macro')\n",
        "xgb_fscore = f1_score (y_test, xgb_pred,average='macro')\n",
        "\n",
        "\n",
        "print('xgb_accuracy with N-GRAM = ',xgb_accuracy)\n",
        "print('xgb_precision with N-GRAM = ',xgb_precision)\n",
        "print('xgb_recall with N-GRAM = ',xgb_recall)\n",
        "print('xgb_Fscore with N-GRAM = ',xgb_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Plot the accuracy comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "accuracies = [knn_accuracy, svm_accuracy,dt_accuracy, xgb_accuracy]\n",
        "plt.bar(models, accuracies)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Precision comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "precisions = [knn_precision, svm_precision,dt_precision, xgb_precision]\n",
        "plt.bar(models, precisions)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('precision')\n",
        "plt.title('Precision comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Recall comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "recalls = [knn_recall, svm_recall,dt_recall, xgb_recall]\n",
        "plt.bar(models, recalls)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Fscore comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "fscores = [knn_fscore, svm_fscore,dt_fscore, xgb_fscore]\n",
        "plt.bar(models, fscores)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Fscore')\n",
        "plt.title('Fscore comparison of models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fc6NsVQeA5_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONFUSION MATRIX AND ERROR ANALYSIS FOR N-GRAM"
      ],
      "metadata": {
        "id": "N0xYolAVYdkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "uk2ut9cUYmRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM ERROR ANALYSIS AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "xGMOoKJpYnOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "svm_pred = svm.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=svm_pred\n",
        "df"
      ],
      "metadata": {
        "id": "DhzeWZ8NBB-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the SVM model with N-GRAM are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), svm_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the SVM model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "xt_IKXYaYqdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for SVM Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lsHoth8R7KKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "kpkA77vqZEQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "knn_pred = knn.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=knn_pred\n",
        "df"
      ],
      "metadata": {
        "id": "hKVqa-u0ZGrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the KNN model with N-GRAM are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), knn_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the KNN model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "N1xqkQDiZH8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for KNN Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tb6HN1tD7Myf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "nsbyvwCNZL-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "dt_pred = dt.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=dt_pred\n",
        "df"
      ],
      "metadata": {
        "id": "2KFkuHkaZOpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the decision tree model with N-GRAM are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), dt_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the Decision Tree model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "ztmuvrLSZRA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for Decision Tree Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hjzWAJGt7PGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost ERROR AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "-4LHdfELZTxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]\n",
        "for i in y_test.index:\n",
        "  temp.append(data['Text'].iloc[i])\n",
        "df=pd.DataFrame(temp,columns=['Text'])\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "df['actual_data']=y_test.to_numpy()\n",
        "df['predicted_data']=xgb_pred\n",
        "df"
      ],
      "metadata": {
        "id": "CPXi2z1TZYc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Count']=df['predicted_data'] == df['actual_data']\n",
        "count=0\n",
        "for i in df['Count']:\n",
        "  if i ==True:\n",
        "    count=count+1\n",
        "df.drop(labels=['Count'],axis=1,inplace=True)\n",
        "print(\"The number of wrong predictions made by the XGBoost model with N-GRAM are:\",200-count)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test.to_numpy(), xgb_pred)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Herman', 'Maria','Chesterton','Jane','Milton'], columns=['Herman', 'Maria','Chesterton','Jane','Milton'])\n",
        "print('\\nThe confusion matrix for the XGBoost model is \\n\\n',conf_matrix_df)\n",
        "print(\"--------------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "5gd0e1NNZaGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix_df, annot=True, fmt='d')\n",
        "plt.title(\"Confusion Matrix for XGBoost Model\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_S1ckmxz7SJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Fold cross validation"
      ],
      "metadata": {
        "id": "OI_wKR19tHnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for SVM \\n\")\n",
        "accuracies=ten_fold_cross_validation(svm,ngrams,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for SVM model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "0JrNDJcMtJt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for KNN \\n\")\n",
        "accuracies=ten_fold_cross_validation(knn,ngrams,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for KNN model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "Sovt-k-mtRq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for Decision Tree \\n\")\n",
        "accuracies=ten_fold_cross_validation(dt,ngrams,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for Decision Tree model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "lW3uTqx3tR8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for XGB \\n\")\n",
        "accuracies=ten_fold_cross_validation(xgb_model,ngrams,data['Author'])\n",
        "print(accuracies)\n",
        "print(\"Bias and Variability for XGB model is\\n\")\n",
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "DBWDWuqTtSGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b08f2f9-74d7-4a19-b1ba-d37a27474f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 fold validation for XGB \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAMPION MODEL = SVM WITH TF-IDF AVERAGING AN ACCURACY OF 0.94"
      ],
      "metadata": {
        "id": "wuX9BGWfBks-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 FOLD COSS VALIDATION FOR CHAMPION MODEL \n"
      ],
      "metadata": {
        "id": "MlIE4GJRBfS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def ten_fold_cross_validation(model, X, y):\n",
        "    kf = KFold(n_splits=10)\n",
        "    accuracy = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        \n",
        "        model.fit(X_train, y_train)\n",
        "        accuracy.append(model.score(X_test, y_test))\n",
        "    \n",
        "    return np.array(accuracy)\n"
      ],
      "metadata": {
        "id": "3Aqs3RN0Be2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 fold validation for SVM \")\n",
        "ten_fold_cross_validation(svm,tfidf,data['Author'])"
      ],
      "metadata": {
        "id": "q9g9rW7mBy4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = ten_fold_cross_validation(svm,bag_of_words,data['Author'])\n",
        "\n",
        "plt.bar(range(1, 11), accuracy, align='center')\n",
        "plt.xticks(range(1, 11))\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('10-Fold Cross Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0gKI5CL-7beh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIAS AND VARIABILITY "
      ],
      "metadata": {
        "id": "3ndxPTU3kIir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bias = 1-np.mean(accuracies)\n",
        "variability = np.std(accuracies)\n",
        "\n",
        "print(\"Bias: {:.3f}\".format(bias))\n",
        "print(\"Variability: {:.3f}\".format(variability))"
      ],
      "metadata": {
        "id": "5_FWndqKjMJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOWERING THE ACCURACY "
      ],
      "metadata": {
        "id": "fc04mNRbcPpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the accuracy of the champion model has been lowered to 0.69 which is approx 20% "
      ],
      "metadata": {
        "id": "XiQGFpcuikRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the csv file\n",
        "#df = pd.read_csv('book_partitions.csv')\n",
        "\n",
        "# Convert the text data into a tf-idf representation\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf = vectorizer.fit_transform(data['Text'].values)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, data['Author'], test_size=0.8, random_state=42)\n",
        "\n",
        "# K-NEAREST NEIGHBOUR \n",
        "# Train and evaluate the KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
        "knn_precision = precision_score(y_test, knn_pred,average='micro')\n",
        "knn_recall = recall_score(y_test, knn_pred,average='micro')\n",
        "knn_fscore = f1_score (y_test, knn_pred,average='micro')\n",
        "\n",
        "print('knn_accuracy with TF-IDF = ',knn_accuracy)\n",
        "print('knn_precision with TF-IDF = ',knn_precision)\n",
        "print('knn_recall with TF-IDF = ',knn_recall)\n",
        "print('knn_Fscore with TF-IDF = ',knn_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#DECISION TREE \n",
        "# Train and evaluate the Decision Tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "dt_precision = precision_score(y_test, dt_pred,average='micro')\n",
        "dt_recall = recall_score(y_test, dt_pred,average='micro')\n",
        "dt_fscore = f1_score (y_test, dt_pred,average='micro')\n",
        "\n",
        "print('dt_accuracy with TF-IDF  = ',dt_accuracy)\n",
        "print('dt_precision with TF-IDF = ',dt_precision)\n",
        "print('dt_recall with TF-IDF = ',dt_recall)\n",
        "print('dt_Fscore with TF-IDF = ',dt_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
        "svm_precision = precision_score(y_test, svm_pred,average='micro')\n",
        "svm_recall = recall_score(y_test, svm_pred,average='micro')\n",
        "svm_fscore = f1_score (y_test, svm_pred,average='micro')\n",
        "\n",
        "\n",
        "print('svm_accuracy with TF-IDF = ',svm_accuracy)\n",
        "print('svm_precision with TF-IDF = ',svm_precision)\n",
        "print('svm_recall with TF-IDF = ',svm_recall)\n",
        "print('svm_Fscore with TF-IDF = ',svm_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Train and evaluate the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
        "xgb_precision = precision_score(y_test, xgb_pred,average='micro')\n",
        "xgb_recall = recall_score(y_test, xgb_pred,average='micro')\n",
        "xgb_fscore = f1_score (y_test, xgb_pred,average='micro')\n",
        "\n",
        "\n",
        "print('xgb_accuracy with TF-IDF = ',xgb_accuracy)\n",
        "print('xgb_precision with TF-IDF = ',xgb_precision)\n",
        "print('xgb_recall with TF-IDF = ',xgb_recall)\n",
        "print('xgb_Fscore with TF-IDF = ',xgb_fscore)\n",
        "print(\"----------------------------------------------------------------\")\n",
        "#++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Plot the accuracy comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "accuracies = [knn_accuracy, svm_accuracy,dt_accuracy, xgb_accuracy]\n",
        "plt.bar(models, accuracies)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Precision comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "precisions = [knn_precision, svm_precision,dt_precision, xgb_precision]\n",
        "plt.bar(models, precisions)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('precision')\n",
        "plt.title('Precision comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Recall comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "recalls = [knn_recall, svm_recall,dt_recall, xgb_recall]\n",
        "plt.bar(models, recalls)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Recall comparison of models')\n",
        "plt.show()\n",
        "\n",
        "# Plot the Fscore comparison of the models\n",
        "models = ['KNN', 'SVM','DT', 'XGBoost']\n",
        "fscores = [knn_fscore, svm_fscore,dt_fscore, xgb_fscore]\n",
        "plt.bar(models, fscores)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Fscore')\n",
        "plt.title('Fscore comparison of models')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kvaSTBbDcPNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}